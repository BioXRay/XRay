#Sampling reads from the fastq files.
#!/bin/bash
echo -e "Usage:\n
        FASTQ_R1 ---Paired-End Sequencing R1 file.\n
        FASTQ_R2 ---Paired-ENd Sequencing R2 file.\n
        Sampled_Pro ---Sampling Proportion.\n
        Outpath ---The path that the sampled results are placed.\n
        Depth ---The fastq depth of coverage.\n"
FASTQ_R1="$1"
FASTQ_R2="$2"
Sampled_Pro="$3"
Outpath="$4"
Depth="$5"
Suffix=".fastq"
MJoin="_sampled_"
if [ $# == "5" ];then
        Prefix_R1=`echo "$FASTQ_R1" | sed "s/\(.*\)\.fastq$/\1/g"`
        Out_R1=${Prefix_R1}${MJoin}${Depth}${Suffix}
        seqkit sample -p $Sampled_Pro -s 123 -o $Outpath/$Out_R1 $FASTQ_R1 #123,200
        echo "R1 file name: $Out_R1"
        Prefix_R2=`echo "$FASTQ_R2" | sed "s/\(.*\)\.fastq$/\1/g"`
        Out_R2=${Prefix_R2}${MJoin}${Depth}${Suffix}
        seqkit sample -p $Sampled_Pro -s 123 -o $Outpath/$Out_R2 $FASTQ_R2 #123,200
        echo "R2 file name: $Out_R2"
fi
echo "The sampleing are finished from the Paired-End FASTQ files."


#Archiving the files
#!/bin/bash

if [ $# -le 1 ];then
        echo -e "Usage:
        \tInputpath\t---The path is placed the CLC analysis results.\n
        \tFILE_OUT\t---The file is saving the extracting information from the duplicate removal report, mapping summary report and Locally repor
        \tOutpath\t---The final files are saved in the path.\n"
        #\tProgram\t---The perl script generates the QC information file.\n
        exit 1
elif [ $# -ge 2 ];then
        PREPATH="/data/clc_result/"
        Inputpath=${PREPATH}"$1""/output"
        #Program="$2" #NGS_Bio_QC_Verify.pl
        FILE_OUT="$2"
        if [ ${FILE_OUT##*.}!="csv" ];then
                FILE_OUT=${FILE_OUT%.*}".csv"
        fi
        DupR="removal" #"duplicate"
        MapS="mapping"
        LocR="coverage"
        echo "Creating the temp work space ......"
        WORKDIR=/home/cdx/Temp_CLC
        if [ ! -d $WORKDIR ];then
                mkdir -p $WORKDIR
        fi
        cd $WORKDIR #/data/clc_result/181218_NB551557_0008_AH55J2AFXY/output
        rm -rf *
        cp $Inputpath/*.* $WORKDIR
        scp cdx@10.20.66.5:/data/PDF/* $WORKDIR
        #cp $Inputpath/*report.pdf $WORKDIR;#cp $Inputpath/*report\).pdf $WORKDIR
        DIR="TransTxt"
        FLAG=0
        SampleName=(`ls $Inputpath | awk -F "_" '{print $1}' | uniq`)
        echo "The total number of the samples: " ${#SampleName[*]}
        echo "Sample Name: " ${SampleName[@]}
        echo "The pdftohtml is used to extract the QC information from some of reports by generated the CLC."
        if [ ! -d $DIR ];then
                mkdir $DIR
        fi
        cd $DIR
        cp $WORKDIR/*report.pdf $WORKDIR/$DIR/
        cp $WORKDIR/*report\).pdf $WORKDIR/$DIR/
        echo "Renamed the pdf file in workspace($DIR)."
        `rename 's/ /_/g' *`
        `rename 's/[(),]//g' *`
        echo "Start process of transforming(xml) ......"
        for Sample in ${SampleName[@]}
        do
                echo "Sample: " $Sample
                if [ `ls ./ | grep "${Sample}_" | grep "$DupR"` ];then
                        FILE_duplicate=`ls ./ | grep "${Sample}_" | grep "$DupR"`
                        echo "${FILE_duplicate}"
                        pdftohtml -i -s -xml -stdout ${FILE_duplicate}
                else
                        echo "The duplicate removal pdf does not exist!!!"
                fi
                if [ `ls ./ | grep "${Sample}_" | grep "$MapS"` ];then
                        FILE_mapping=`ls ./ | grep "${Sample}_" | grep "$MapS"`
                        echo "${FILE_mapping}"
                        pdftohtml -i -s -xml -stdout ${FILE_mapping}
                else
                        echo "The mapping report pdf does not exist!!!"
                fi
                if [ `ls ./ | grep "${Sample}_" | grep "$LocR"` ];then
                        FILE_Locally=`ls ./ | grep "${Sample}_" | grep "$LocR"`
                        echo "${FILE_Locally}"
                        pdftohtml -i -s -xml -stdout ${FILE_Locally}
                else
                        echo "The locally report pdf does not exist!!!"
                fi
                if [ `ls ./ | grep "${Sample}_" | grep "$DupR" | grep "xml"` ];then
                        File_dup=`ls ./ | grep "${Sample}_" | grep "$DupR" | grep "xml"`
                else
                        File_dup="$Sample""_duplicate_removal_report.xml"
                fi
                if [ `ls ./ | grep "${Sample}_" | grep "$MapS" | grep "xml"` ];then
                        File_map=`ls ./ | grep "${Sample}_" | grep "$MapS" | grep "xml"`
                else
                        File_map="$Sample""_mapping_summary_report.xml"
                fi
                if [ `ls ./ | grep "${Sample}_" | grep "$LocR" | grep "xml"` ];then
                        File_Loc=`ls ./ | grep "${Sample}_" | grep "$LocR" | grep "xml"`
                else
                        File_Loc="$Sample""_Locally_Realigned_coverage_report.xml"
                fi
                echo "Transformed files(xml): "
                echo "${File_dup}"
                echo "${File_map}"
                echo "${File_Loc}"
                FLAG=`expr $FLAG + 1`
                echo "$FLAG"
                perl /data/fastq_raw_data/Sampling/Test_CLC_Pipeline/WXDX_NGS_QC_Extract_v2.pl $File_dup $File_map $File_Loc $FILE_OUT $FLAG $In
        done
        mv $FILE_OUT ../
        cd $WORKDIR
        `rename 's/ /_/g' *`
        `rename 's/[(),]//g' *`
        #The all files are ready, and then those files are archived to public directory for reviewing in Lab.
        echo -e "The all files have been readying to be archived.\nStarting archiving ......\n"
        OLD_IFS="$IFS"
        IFS="/"
        PATH_INFO=($Inputpath)
        IFS="$OLD_IFS"
        INDEX=`expr ${#PATH_INFO[*]} - 2`
        CLC_BATCH_RUN=${PATH_INFO[$INDEX]}
        if [ ! $3 ];then
                Outpath="/data/WXDX_NGS"
        else
                Outpath="$3"
        fi
        cd $Outpath
        if [ ! -d $CLC_BATCH_RUN ];then
                mkdir $CLC_BATCH_RUN
        fi
        FileName=(`ls $Inputpath | awk -F "_" '{print $1}' | uniq`)
        #NGS_PROJECT=(`ls $Inputpath | awk -F "_" '{print $1}' | awk -F "-" '{print $1}' | uniq`)
        cd $CLC_BATCH_RUN
        for PROJECT in ${FileName[@]}
        do
                echo "Project: " $PROJECT
                NGS_DIR=`echo $PROJECT | sed "s/\(^[A-Z0-9]*[-][A-Z0-9]*\)[-].*/\1/g"`
                echo "Dir: " $NGS_DIR
                if [ ! -d $NGS_DIR ];then
                        mkdir $NGS_DIR
                        MOVEL_FILE=(`ls $WORKDIR | grep "$NGS_DIR"`)
                        echo "The total number of the moving files(Prefix $NGS_DIR): " ${#MOVEL_FILE[*]}
                        for FILE in ${MOVEL_FILE[@]}
                        do
                                mv $WORKDIR/$FILE $NGS_DIR/
                        done
                fi
        done
        if [ -f $WORKDIR/$FILE_OUT ];then
                mv $WORKDIR/$FILE_OUT $Outpath/$CLC_BATCH_RUN
        else
                echo "This NGS project does not need to extract QC information from the CLC analysis results!!!"
        fi
        echo "All the files have been archived."
fi

#
#!/usr/bin/perl -w
#use strict;
my $a="Number of target regions with coverage below 100 ";
#chomp($mySTR);
$a =~m/(\d+)/g;
$a =~s/(\d+)/$1/g;
print "$&\n";
print "$a\n";


#
##############################################################################################################
#                                                                                                            #
#       LUNGR (RNA Fusion Panel for Lung Cancer), Auto Reporting Pipline, written by Bo Wang at WXDX         #
#                                                                                                            #
###Initialization#############################################################################################

$project=$ARGV[0];
$dir_fastq="/data/fastq_raw_data/$project";
$dir_clc="/data/clc_result/$project/output";

$usage="Usage: perl getFusionResults.pl <PROJECT>\n";
$error1="!!Error: FASTQ_DIR $project does not exist\nUsage: perl getFusionResults.pl <PROJECT>\n";
$error2="!!Error: CLC_DIR $project does not exist\nUsage: perl getFusionResults.pl <PROJECT>\n";

die $usage if $#ARGV != 0;
die $error1 if !-e $dir_fastq;
die $error2 if !-e $dir_clc;

@list=`ls $dir_fastq|grep LUNGR`;

foreach(@list){
        chomp;
        @line=split(/\./,$_);
        if($line[0] =~ /(.*)_R1_001/){
                push(@sample,$1);
        }
}

#############################################################################################################

###Total Reads - FastQC######################################################################################

if(!-e "$dir_clc/QC"){
        `mkdir $dir_clc/QC`;
}

`fastqc -q -t 16 -o $dir_clc/QC $dir_fastq/LUNGR*`;
`unzip '$dir_clc/QC/*.zip'`;

for($i=0;$i<=$#sample;$i++){
        $s=$sample[$i];
        $r1="$s\_R1\_001\_fastqc/fastqc_data.txt";
        $r2="$s\_R2\_001\_fastqc/fastqc_data.txt";
        if(!-e $r1){
                die "!!Error: $r1 does not exist\n";
        }
        open(DATA,$r1);
        while(<DATA>){
                chomp;
                if(/Total\sSequences\t(\d+)/){
                        $hash_total{$s}=$1;
                        last;
                }
        }
        close(DATA);

        if(!-e $r2){
                die "!!Error: $r2 does not exist\n";
        }
        open(DATA,$r2);
        while(<DATA>){
                chomp;
                if(/Total\sSequences\t(\d+)/){
                        $hash_total{$s}+=$1;
                        last
                }
        }
        close(DATA);
}

open(FILE,">$dir_clc/QC/total_reads.txt");
foreach(keys %hash_total){
        print FILE "$_\t$hash_total{$_}\n";
}
close(FILE);
`rm -rf *fastqc`;

#############################################################################################################

###Mapped Reads - Samtools###################################################################################

open(FILE,">$dir_clc/QC/mapped_reads.txt");
for($i=0;$i<=$#sample;$i++){
        $s=$sample[$i];
        $bam="$dir_clc/'$s\_R1\_001 (paired) trimmed (paired) RNA-Seq (Reads).bam'";
        $unmap="$dir_clc/'$s\_R1\_001 (paired) trimmed (paired) RNA-Seq un-mapped reads [$s\_R1\_001] (single).txt'";

        $stat=`samtools flagstat -@ 16 $bam`;
        if($stat =~ /(\w+)./){
                $hash_map{$s}=$1;
        }

        $num=`wc -l $unmap`;
        $hash_unmap{$s}=$num-2;

        print FILE "$s\t$hash_map{$s}\t$hash_unmap{$s}\n";

        $cover="$dir_clc/$s\_R1\_001\ (paired)\ trimmed\ (paired)\ RNA-Seq\ (Reads,\ coverage).txt";
        if(!-e $cover){
                die "!!Error: $cover does not exist\n";
        }
        open(DATA,$cover);
        while(<DATA>){
                chomp;
                $_=~s/\"//g;
                @line=split(/\t/,$_);
                $hash_expr{$line[2]}=$line[7];
        }
        close(DATA);
        $ctr{$s}=$hash_expr{'HMBS'}+$hash_expr{'ITGB7'}+$hash_expr{'LMNA'}+$hash_expr{'MYC'}+$hash_expr{'TBP'};
        $hash_score{'ALK'}{$s}=100*($hash_expr{'ALK_3P'}-$hash_expr{'ALK_5P'})/$ctr{$s};
        $hash_score{'RET'}{$s}=100*($hash_expr{'RET_3P'}-$hash_expr{'RET_5P'})/$ctr{$s};
        $hash_score{'ROS1'}{$s}=100*($hash_expr{'ROS1_3P'}-$hash_expr{'ROS1_5P'})/$ctr{$s};
        $hash_score{'NTRK1'}{$s}=100*($hash_expr{'NTRK1_3P'}-$hash_expr{'NTRK1_5P'})/$ctr{$s};
}
close(FILE);

#############################################################################################################

###Result####################################################################################################

if(!-e "$dir_clc/results"){
        `mkdir $dir_clc/results`;
}

%cutoff=(
        'ALK' => 2,
        'RET' => 10,
        'ROS1' => 20,
        'NTRK1' => 10,
);

foreach(@sample){
        $s=$_;
        $result="$dir_clc/$s\_R1\_001\ (paired)\ Fusion\ genes.txt";

        if(!-e $result){
                die "!!Error: $result does not exist\n";
        }
        open(DATA,$result);
        open(FILE,">$dir_clc/results/$s.csv");

        print FILE "Total Reads:\,$hash_total{$s}\,";
        if($hash_total{$s} >= 10000){
                print FILE "PASS\n";
        }else{
                print FILE "WARNING!!\n";
        }

        print FILE "Internal Expression Control Reads:\,$ctr{$s}\,";
        if($ctr{$s} >= 5000){
                print FILE "PASS\n";
        }else{
                print FILE "WARNING!!\n";
        }

        print FILE "Mapped Reads:\,$hash_map{$s}\n";

        $ratio=100*$hash_map{$s}/($hash_map{$s} + $hash_unmap{$s});
        printf FILE "Reads Mapped to Reference:\,%.2f\%\,",$ratio;
        if($ratio >= 20){
                print FILE "PASS\n\n\n";
        }else{
                print FILE "WARNING!!\n\n\n";
        }

        print FILE "Fusion\,Fusion Reads\,Z-score\,P-value\,CLC-filter\,\%Targeted Fusion Reads\,3'\/5' score\,Mayo-Filter\,Found in-frame CDS\,
        $n=0;
        while(<DATA>){
                chomp;
                if($n == 0){
                        $n=1;
                }else{
                        $_=~s/\"//g;
                        @line=split(/\t/,$_);

                        $targetReads=sprintf "%.2f\%",100*$line[7]/$hash_total{$s};

                        if($line[7] < 30){
                                if($hash_score{$line[5]}{$s} < $cutoff{$line[5]}){
                                        $filter="NEGATIVE";
                                }else{
                                        $filter="FISH";
                                }
                        }elsif($line[7] >= 100){
                                if($targetReads >= 0.1){
                                        $filter="POSTIVE";
                                }else{
                                        $filter="UNKNOWN";
                                }
                        }else{
                                if($targetReads >= 0.1){
                                        $filter="REPEAT or FISH";
                                }else{
                                        $filter="REPEAT or NEGATIVE";
                                }
                        }
                        if(exists $hash_score{$line[5]}{$s}){
                                $score=sprintf "%.2f",$hash_score{$line[5]}{$s};
                        }else{
                                $score="NOT REPORTABLE";
                        }
                        if($line[10] =~ /\d+/){
                                $zscore=sprintf "%.2f",$line[10];
                        }else{
                                $zscore=" $line[10]";
                        }
                        print FILE "$line[2]\,$line[7]\,$zscore\,$line[11]\,$line[12]\,$targetReads\,$score\,$filter\,$line[14]\,$line[16]\, $li
                }
        }
        close(DATA,FILE);
}

#############################################################################################################
##http://resources.qiagenbioinformatics.com/manuals/clcserver/current/admin/index.php?manual=Command_line_tools.html(CLC analysis tool)###
Dynamic Risk Profiling Using Serial Tumor Biomarkers for Personalized Outcome Prediction



###################################
rm
#!/usr/bin/env python

from pathlib import Path
from datetime import datetime
from dateutil.parser import *
import subprocess

p = Path('/data/monkey_genewiz/wdl_wgs/cromwell-executions/macfas_GATK4_WGS_VariantDiscovery_pipeline')
p = Path('/data/macfas_data/wdl_wgs/cromwell-executions/macfas_GATK4_WGS_VariantDiscovery_pipeline')

dirs = [g for g in p.glob('*') if g.is_dir()]

end_date = parse('2019 11 25 2:00')
dirs = [ d for d in dirs if datetime.fromtimestamp(d.stat().st_mtime) < end_date]

for d in dirs:
    try:    
        print(d, datetime.fromtimestamp(d.stat().st_mtime))
        print(f'rm -rf {str(d.resolve())}')
        subprocess.run(f'rm -rf {str(d.resolve())}', shell=True)
    except Exception as e:
        print(e)
        pass
##############################################################
#!/usr/bin/python
#
#     demultiplex_undetermined_fastq.py: demultiplex undetermined Illumina reads
#     Copyright (C) University of Manchester 2013 Peter Briggs
#
########################################################################
#
# demultiplex_undetermined_fastq.py
#
#########################################################################

"""demultiplex_undetermined_fastq.py

Attempts to demultiplex the reads in the "Undetermined_indices" directory
produced by a CASAVA run, by barcode (i.e. index sequences) matching in
the read headers.

This program was originally written to deal with HiSEQ data where
dual-indexed and single indexed barcoding protocols were mixed in the same
sequencing run.

"""

#######################################################################
# Import modules that this module depends on
#######################################################################

__version__ = "0.0.1"

import os
import sys
import optparse

# Put .. onto Python search path for modules
SHARE_DIR = os.path.abspath(
    os.path.normpath(
        os.path.join(os.path.dirname(sys.argv[0]),'..')))
sys.path.append(SHARE_DIR)
import bcftbx.IlluminaData as IlluminaData
import bcftbx.FASTQFile as FASTQFile

#######################################################################
# Class definitions
#######################################################################

class BarcodeMatcher:
    """BarcodeMatcher

    Class for testing whether a sequence matches a barcode.

    Example usage:
    >>> b = BarcodeMatcher("ACCTAG")
    >>> b.match("ACCTAC") # returns False, exact match required
    >>> b.match("ACCTAC",max_mismatches=1) # returns True, one mismatch

    """

    def __init__(self,barcode):
        """Create a new BarcodeMatcher

        Arguments:
          barcode: barcode (i.e. index) sequence to test against

        """
        self.__barcode = barcode

    @property
    def barcode(self):
        """Return the stored barcode/index sequence.

        """
        return self.__barcode

    def match(self,test_barcode,max_mismatches=0):
        """Test a barcode/index sequence against the stored sequence

        Arguments:
          test_barcode: barcode/index sequence being tested
          max_mismatches: maximum number of mismatches allowed while
            still considering the two sequences to match (default is
            zero i.e. no mismatches)

        Returns:
          True if test barcode matches the reference, False otherwise.

        """
        if test_barcode.startswith(self.__barcode):
            return True
        nmismatches = 0
        try:
            for i in range(len(self.__barcode)):
                if test_barcode[i] != self.__barcode[i]:
                    nmismatches += 1
                    if nmismatches > max_mismatches:
                        return False
        except IndexError:
            return False
        return True

#######################################################################
# Module Functions
#######################################################################

def demultiplex_fastq(fastq_file,barcodes,nmismatches):
    """Perform demultiplexing of a FASTQ file

    Demultiplex reads in a FASTQ file given information about a set of 
    barcode/index sequences.

    Produces a file for each barcode, plus another for 'unbinned'
    reads.

    Arguments:
      fastq_file: FASTQ file to be demultiplexed (can be gzipped)
      barcodes: list of barcode sequences to use for demultiplexing
      nmismatches: maxiumum number of mismatched bases allowed when
        testing whether barcode sequences match

    Returns:
      No return value
    """
    # Start
    print "Processing %s" % fastq_file
    info = IlluminaData.IlluminaFastq(fastq_file)
    # Set up output files
    output_files = {}
    # Weed out barcodes that aren't associated with this lane
    local_barcodes = []
    for barcode in barcodes:
        if barcode['lane'] != info.lane_number:
            continue
        local_barcodes.append(barcode)
        output_file_name = "%s_%s_L%03d_R%d_%03d.fastq" % (barcode['name'],
                                                           barcode['index'],
                                                           info.lane_number,
                                                           info.read_number,
                                                           info.set_number)
        print "\t%s\t%s" % (barcode['index'],output_file_name)
        if os.path.exists(output_file_name):
            print "\t%s: already exists,exiting" % output_file_name
            sys.exit(1)
        output_files[barcode['index']] = open(output_file_name,'w')
    # Check if there's anything to do
    if len(local_barcodes) == 0:
        return
    # Also make a file for unbinned reads
    unbinned_file_name = "unbinned_L%03d_R%d_%03d.fastq" % (info.lane_number,
                                                            info.read_number,
                                                            info.set_number)
    if os.path.exists(unbinned_file_name):
        print "\t%s: already exists,exiting" % unbinned_file_name
        sys.exit(1)
    output_files['unbinned'] = open(unbinned_file_name,'w')
    # Process reads
    nreads = 0
    for read in FASTQFile.FastqIterator(fastq_file):
        nreads += 1
        matched_read = False
        this_barcode = read.seqid.index_sequence
        for barcode in local_barcodes:
            if barcode['matcher'].match(this_barcode,nmismatches):
                ##print "Matched %s against %s" % (this_barcode,barcodes[barcode]['name'])
                output_files[barcode['index']].write(str(read)+'\n')
                matched_read = True
                break
        # Put in unbinned if no match
        if not matched_read:
            output_files['unbinned'].write(str(read)+'\n')
        ##if nreads > 100: break
    # Close files
    for barcode in local_barcodes:
        output_files[barcode['index']].close()
    print "\tMatched %d reads for %s" % (nreads,os.path.basename(fastq_file))

#######################################################################
# Main program
#######################################################################

if __name__ == "__main__":

    # Create command line parser
    p = optparse.OptionParser(usage="%prog OPTIONS DIR",
                              version="%prog "+__version__,
                              description="Reassign reads with undetermined index sequences. "
                              "(i.e. barcodes). DIR is the name (including any leading path) "
                              "of the 'Undetermined_indices' directory produced by CASAVA, "
                              "which contains the FASTQ files with the undetermined reads from "
                              "each lane.")
    p.add_option("--barcode",action="append",dest="barcode_info",default=[],
                 help="specify barcode sequence and corresponding sample name as BARCODE_INFO. "
                 "The syntax is '<name>:<barcode>:<lane>' e.g. --barcode=PB1:ATTAGA:3")
    p.add_option("--samplesheet",action="store",dest="sample_sheet",default=None,
                 help="specify SampleSheet.csv file to read barcodes, sample names and lane "
                 "assignments from (as an alternative to --barcode).")

    # Parse command line
    options,args = p.parse_args()

    # Get data directory name
    if len(args) != 1:
        p.error("expected one argument (location of undetermined index reads)")
    undetermined_dir = os.path.abspath(args[0])

    # Set up barcode data
    barcodes = []
    for barcode_info in options.barcode_info:
        name,barcode,lane = barcode_info.split(':')
        print "Assigning barcode '%s' in lane %s to %s" % (barcode,lane,name)
        barcodes.append({ 'name': name,
                          'index': barcode,
                          'matcher': BarcodeMatcher(barcode),
                          'lane': int(lane)})

    # Read from sample sheet (if supplied)
    if options.sample_sheet is not None:
        print "Reading data from sample sheet %s" % options.sample_sheet
        sample_sheet = IlluminaData.CasavaSampleSheet(options.sample_sheet)
        for line in sample_sheet:
            name = line['SampleID']
            barcode = line['Index'].rstrip('N').rstrip('-').rstrip('N')
            lane = line['Lane']
            print "Assigning barcode '%s' in lane %s to %s" % (barcode,lane,name)
            barcodes.append({ 'name': name,
                              'index': barcode,
                              'matcher': BarcodeMatcher(barcode),
                              'lane': int(lane) })
    if len(barcodes) < 1:
        p.error("need at least one --barcode and/or --samplesheet assignment")

    # Collect input files
    p = IlluminaData.IlluminaProject(undetermined_dir)

    # Loop over "samples" and match barcodes
    for s in p.samples:
        for fq in s.fastq:
            fastq = os.path.join(s.dirn,fq)
            demultiplex_fastq(fastq,barcodes,1)
    print "Finished"



